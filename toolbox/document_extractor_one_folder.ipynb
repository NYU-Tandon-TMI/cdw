{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c642814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF is for splitting pdf docs\n",
    "import difflib\n",
    "import pandas as pd\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai\n",
    "\n",
    "project_id = \"nyc-ddc-cdc4\"\n",
    "location = \"us\"\n",
    "processor_id = \"12fdd9cc0a336340\" # Create processor before running sample\n",
    "file_path = \"2A-033_ConEd_cdd.2019-02G.wtd.pdf\"\n",
    "mime_type = \"application/pdf\" # Refer to https://cloud.google.com/document-ai/docs/file-types for supported file types\n",
    "field_mask = \"entities\" #Optional. The fields to return in the Document object.\n",
    "processor_version_id = \"pretrained-foundation-model-v1.0-2023-08-22\" # Optional. Processor version to use\n",
    "\n",
    "opts = ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
    "client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "processor_name = client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "columns = ['type_debris',\n",
    "           'waste_quantity',\n",
    "           'pickup_name',\n",
    "           'pickup_address',\n",
    "           'pickup_city',\n",
    "           'pickup_state',\n",
    "           'pickup_zip',\n",
    "           'pickup_lat',\n",
    "           'pickup_lng',\n",
    "           'generator_name',\n",
    "           'generator_address',\n",
    "           'generator_city',\n",
    "           'generator_state',\n",
    "           'generator_zip',\n",
    "           'transporter_name',\n",
    "           'receiving_name',\n",
    "           'receiving_address',\n",
    "           'receiving_city',\n",
    "           'receiving_state',\n",
    "           'receiving_zip',\n",
    "           'receiving_lat',\n",
    "           'receiving_lng',\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dece3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_type(text, cutoff=0.6):\n",
    "    candidates = ['Limited-Use Fill',\n",
    "                  'Restricted-Use Fill',\n",
    "                  'Contaminated Fill',\n",
    "                  'Fill Material - Unknown',\n",
    "                  'General Fill',\n",
    "                  'Residue',\n",
    "                  'Construction Waste',\n",
    "                  'Demolition Waste'\n",
    "                 ]\n",
    "    matches = difflib.get_close_matches(text, candidates, n=1, cutoff=cutoff)\n",
    "    if matches:\n",
    "        return matches[0]  # Return the closest match found\n",
    "    return 'Mix'  # Return 'Mix' if no close match is found\n",
    "    \n",
    "\n",
    "def process_data(text: str) -> str:\n",
    "    return text.replace(\"\\n\", \" \")\n",
    "\n",
    "def process_page(page):\n",
    "    image = page.get_pixmap()\n",
    "    image_bytes = image.tobytes(\"png\")  # Convert the page to PNG bytes\n",
    "\n",
    "    # Create a document\n",
    "    raw_document = documentai.RawDocument(content=image_bytes, mime_type='image/png')\n",
    "\n",
    "    # Create a request\n",
    "    request = documentai.ProcessRequest(name=processor_name, raw_document=raw_document)\n",
    "\n",
    "    # Process the document\n",
    "    result = client.process_document(request=request)\n",
    "    page_data = {col: '' for col in columns} # Initial a blank row\n",
    "    for entity in result.document.entities:\n",
    "        if entity.type_ in page_data: # Check if it is required\n",
    "            if entity.type_ == 'type_debris':\n",
    "                page_data[entity.type_] = process_type(entity.mention_text)\n",
    "            else:\n",
    "                page_data[entity.type_] = process_data(entity.mention_text)\n",
    "    return page_data\n",
    "\n",
    "def process_pdf(file_path, csv_file_path):\n",
    "    doc = fitz.open(file_path)  # Open the PDF file\n",
    "    data = []\n",
    "    for page_num, page in enumerate(doc, start=1):\n",
    "        print(f\"Processing page {page_num}\")\n",
    "        page_data = process_page(page)\n",
    "        data.append(page_data)\n",
    "    \n",
    "    # Create DataFrame and save it to CSV\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(csv_file_path, mode='a', header=False, index=False)\n",
    "    \n",
    "def process_folder(folder_path, csv_file_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith('.pdf'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "            process_pdf(file_path, csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68233f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: NYS Tracking Documents/R1/1A-301 PARK TRUCKING, INC\\1A-301_Park_Trucking_cdd.2021-09D.wtd.pdf\n",
      "Processing page 1\n",
      "Processing page 2\n",
      "Processing page 3\n",
      "Processing page 4\n",
      "Processing page 5\n",
      "Processing page 6\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "500 Internal error encountered.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterim_csv.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNYS Tracking Documents/R1/1A-301 PARK TRUCKING, INC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m process_folder(folder_path, csv_file_path)\n",
      "Cell \u001b[1;32mIn[2], line 58\u001b[0m, in \u001b[0;36mprocess_folder\u001b[1;34m(folder_path, csv_file_path)\u001b[0m\n\u001b[0;32m     56\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, filename)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m process_pdf(file_path, csv_file_path)\n",
      "Cell \u001b[1;32mIn[2], line 46\u001b[0m, in \u001b[0;36mprocess_pdf\u001b[1;34m(file_path, csv_file_path)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_num, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(doc, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m     page_data \u001b[38;5;241m=\u001b[39m process_page(page)\n\u001b[0;32m     47\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend(page_data)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Create DataFrame and save it to CSV\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 31\u001b[0m, in \u001b[0;36mprocess_page\u001b[1;34m(page)\u001b[0m\n\u001b[0;32m     28\u001b[0m request \u001b[38;5;241m=\u001b[39m documentai\u001b[38;5;241m.\u001b[39mProcessRequest(name\u001b[38;5;241m=\u001b[39mprocessor_name, raw_document\u001b[38;5;241m=\u001b[39mraw_document)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Process the document\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m result \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mprocess_document(request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m     32\u001b[0m page_data \u001b[38;5;241m=\u001b[39m {col: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns} \u001b[38;5;66;03m# Initial a blank row\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdocument\u001b[38;5;241m.\u001b[39mentities:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\cloud\\documentai_v1\\services\\document_processor_service\\client.py:899\u001b[0m, in \u001b[0;36mDocumentProcessorServiceClient.process_document\u001b[1;34m(self, request, name, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    898\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 899\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[0;32m    900\u001b[0m     request,\n\u001b[0;32m    901\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[0;32m    902\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    903\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    904\u001b[0m )\n\u001b[0;32m    906\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    294\u001b[0m     target,\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[0;32m    296\u001b[0m     sleep_generator,\n\u001b[0;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[0;32m    299\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     _retry_error_helper(\n\u001b[0;32m    154\u001b[0m         exc,\n\u001b[0;32m    155\u001b[0m         deadline,\n\u001b[0;32m    156\u001b[0m         sleep,\n\u001b[0;32m    157\u001b[0m         error_list,\n\u001b[0;32m    158\u001b[0m         predicate,\n\u001b[0;32m    159\u001b[0m         on_error,\n\u001b[0;32m    160\u001b[0m         exception_factory,\n\u001b[0;32m    161\u001b[0m         timeout,\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mInternalServerError\u001b[0m: 500 Internal error encountered."
     ]
    }
   ],
   "source": [
    "csv_file_path = 'interim_csv.csv'\n",
    "folder_path = \"NYS Tracking Documents/R1/1A-301 PARK TRUCKING, INC\"\n",
    "\n",
    "process_folder(folder_path, csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72371c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
